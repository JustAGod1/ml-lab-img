{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T13:25:54.395905Z",
     "start_time": "2025-04-10T13:25:37.931295Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torchvision\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import io\n",
    "\n",
    "from torchvision.datasets import MNIST\n"
   ],
   "id": "fbc121e30a2defb3",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T13:25:54.403881Z",
     "start_time": "2025-04-10T13:25:54.397478Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ],
   "id": "bb9ae6d2db628048",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T13:25:54.516147Z",
     "start_time": "2025-04-10T13:25:54.401605Z"
    }
   },
   "cell_type": "code",
   "source": [
    "plt.plot([1, 2, 3, 4])\n",
    "plt.ylabel('some numbers')\n",
    "plt.show()"
   ],
   "id": "6bafc75e835a9c64",
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T13:25:54.659809Z",
     "start_time": "2025-04-10T13:25:54.518599Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_data_fmnist = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True, transform=torchvision.transforms.ToTensor())\n",
    "test_data_fmnist = torchvision.datasets.FashionMNIST(root='./data', train=False, download=True, transform=torchvision.transforms.ToTensor())\n",
    "\n",
    "train_data_mnist = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=torchvision.transforms.ToTensor())\n",
    "test_data_mnist = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=torchvision.transforms.ToTensor())\n",
    "\n"
   ],
   "id": "214c5eeedde32bf1",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T13:25:54.685476Z",
     "start_time": "2025-04-10T13:25:54.665529Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device =  \"cpu\"\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.shared_layers  = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3),  # 1 input channel, 32 output channels\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten(),  # Flatten before Linear layers\n",
    "            nn.Linear(64 * 5 * 5, 512),  # Adjusted for MNIST after convs\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.head1 = nn.Linear(512, 10)\n",
    "        self.head2 = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x, head=1):\n",
    "        x = self.flatten(x)\n",
    "        x = self.shared_layers(x)\n",
    "        \n",
    "        if head == 1:\n",
    "            return self.head1(x)  \n",
    "        else:\n",
    "            return self.head2(x) \n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ],
   "id": "20e55314a5b8a588",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (shared_layers): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Flatten(start_dim=1, end_dim=-1)\n",
      "    (7): Linear(in_features=1600, out_features=512, bias=True)\n",
      "    (8): ReLU()\n",
      "  )\n",
      "  (head1): Linear(in_features=512, out_features=10, bias=True)\n",
      "  (head2): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T13:25:54.685831Z",
     "start_time": "2025-04-10T13:25:54.679403Z"
    }
   },
   "cell_type": "code",
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "batch_size = 64\n",
    "def make_data_loader(data) -> torch.utils.data.DataLoader:\n",
    "    return torch.utils.data.DataLoader(data, batch_size=batch_size)"
   ],
   "id": "ab6709dea383d5b6",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T13:25:54.708062Z",
     "start_time": "2025-04-10T13:25:54.682953Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train(data, model, parameters, head: int) -> [float]:\n",
    "    optimizer = torch.optim.SGD(parameters, lr=1e-3)\n",
    "    steps = []\n",
    "    model.train()\n",
    "    dataloader = make_data_loader(data)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X, head=head)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        steps.append(loss.item())\n",
    "        \n",
    "    return steps"
   ],
   "id": "b290bd63f09da556",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T13:25:54.708914Z",
     "start_time": "2025-04-10T13:25:54.689326Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def test(data, model, head: int) -> (float, float):\n",
    "    dataloader = make_data_loader(data)\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X, head=head)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    \n",
    "    return correct, test_loss"
   ],
   "id": "6ae432369572d3c0",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T13:25:54.709249Z",
     "start_time": "2025-04-10T13:25:54.699648Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class EpochResult:\n",
    "    def __init__(self, steps: [float], correct: float, test_loss: float):\n",
    "        self.steps = steps\n",
    "        self.correct = correct\n",
    "        self.test_loss = test_loss\n",
    "\n",
    "\n",
    "\n",
    "def run_training(train_data, test_data, model, parameters, head: int) -> [EpochResult]:\n",
    "    epoch_results = []\n",
    "    epochs = 5\n",
    "    for t in range(epochs):\n",
    "        steps = train(train_data, model, parameters, head)\n",
    "        correct, test_loss = test(test_data, model, head)\n",
    "        \n",
    "        epoch_results.append(EpochResult(steps, correct, test_loss))\n",
    "    \n",
    "    return epoch_results\n",
    "    "
   ],
   "id": "9f35dab1c8a6f838",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Training on MNIST"
   ],
   "id": "9a2567b3cbadd027"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T13:25:54.724678Z",
     "start_time": "2025-04-10T13:25:54.707004Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def plot_learning(r: [EpochResult]):\n",
    "    loses = []\n",
    "    correctness = []\n",
    "    vlines = []\n",
    "    last = 0\n",
    "\n",
    "    for data in r:\n",
    "        loses.extend(np.array(data.steps))\n",
    "        correctness.append(data.correct)\n",
    "        last += len(data.steps)\n",
    "        vlines.append(last)\n",
    "\n",
    "    def moving_average(data, window_size):\n",
    "        cumsum = np.cumsum(np.insert(data, 0, 0)) \n",
    "        return (cumsum[window_size:] - cumsum[:-window_size]) / window_size\n",
    "        \n",
    "    plt.title(\"loses\")\n",
    "    plt.plot(loses, label=\"losses\")\n",
    "    plt.plot(moving_average(loses, 50), label=\"losses moving average\")\n",
    "\n",
    "    for vline in vlines:\n",
    "        plt.axvline(vline, color=\"red\")\n",
    "\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    plt.title(\"correctness\")\n",
    "    plt.plot(correctness)\n",
    "    plt.show()\n",
    "    \n",
    "    correct_mnist, _ = test(test_data_mnist, model, head=1)\n",
    "    correct_fmnist, _ = test(test_data_fmnist, model, head=2)\n",
    "    \n",
    "    plt.title(\"Correction comparison\")\n",
    "    plt.bar([\"MNIST\", \"FashionMNIST\"], [correct_mnist * 100, correct_fmnist * 100])\n",
    "    plt.ylim([0, 100])\n",
    "    plt.show()\n"
   ],
   "id": "cf8b60f71dd13bc1",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T13:25:55.441623Z",
     "start_time": "2025-04-10T13:25:54.712755Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mnist_learning = run_training(train_data_mnist, test_data_mnist, model, list(model.parameters()), 1)"
   ],
   "id": "8d229999b84a7f0c",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected 3D (unbatched) or 4D (batched) input to conv2d, but got input of size: [64, 784]",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mRuntimeError\u001B[39m                              Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[11]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m mnist_learning = \u001B[43mrun_training\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_data_mnist\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_data_mnist\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m.\u001B[49m\u001B[43mparameters\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[9]\u001B[39m\u001B[32m, line 13\u001B[39m, in \u001B[36mrun_training\u001B[39m\u001B[34m(train_data, test_data, model, parameters, head)\u001B[39m\n\u001B[32m     11\u001B[39m epochs = \u001B[32m5\u001B[39m\n\u001B[32m     12\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(epochs):\n\u001B[32m---> \u001B[39m\u001B[32m13\u001B[39m     steps = \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_data\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparameters\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhead\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     14\u001B[39m     correct, test_loss = test(test_data, model, head)\n\u001B[32m     16\u001B[39m     epoch_results.append(EpochResult(steps, correct, test_loss))\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[7]\u001B[39m\u001B[32m, line 10\u001B[39m, in \u001B[36mtrain\u001B[39m\u001B[34m(data, model, parameters, head)\u001B[39m\n\u001B[32m      7\u001B[39m X, y = X.to(device), y.to(device)\n\u001B[32m      9\u001B[39m \u001B[38;5;66;03m# Compute prediction error\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m10\u001B[39m pred = \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhead\u001B[49m\u001B[43m=\u001B[49m\u001B[43mhead\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     11\u001B[39m loss = loss_fn(pred, y)\n\u001B[32m     13\u001B[39m \u001B[38;5;66;03m# Backpropagation\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/ml-lab-img/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1509\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1510\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1511\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/ml-lab-img/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1515\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1516\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1517\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1518\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1519\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1520\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1522\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m   1523\u001B[39m     result = \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[5]\u001B[39m\u001B[32m, line 24\u001B[39m, in \u001B[36mNeuralNetwork.forward\u001B[39m\u001B[34m(self, x, head)\u001B[39m\n\u001B[32m     22\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x, head=\u001B[32m1\u001B[39m):\n\u001B[32m     23\u001B[39m     x = \u001B[38;5;28mself\u001B[39m.flatten(x)\n\u001B[32m---> \u001B[39m\u001B[32m24\u001B[39m     x = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mshared_layers\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     26\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m head == \u001B[32m1\u001B[39m:\n\u001B[32m     27\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.head1(x)  \n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/ml-lab-img/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1509\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1510\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1511\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/ml-lab-img/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1515\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1516\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1517\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1518\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1519\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1520\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1522\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m   1523\u001B[39m     result = \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/ml-lab-img/venv/lib/python3.11/site-packages/torch/nn/modules/container.py:217\u001B[39m, in \u001B[36mSequential.forward\u001B[39m\u001B[34m(self, input)\u001B[39m\n\u001B[32m    215\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[32m    216\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[32m--> \u001B[39m\u001B[32m217\u001B[39m         \u001B[38;5;28minput\u001B[39m = \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m    218\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/ml-lab-img/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1509\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1510\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1511\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/ml-lab-img/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1515\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1516\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1517\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1518\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1519\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1520\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1522\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m   1523\u001B[39m     result = \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/ml-lab-img/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py:460\u001B[39m, in \u001B[36mConv2d.forward\u001B[39m\u001B[34m(self, input)\u001B[39m\n\u001B[32m    459\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) -> Tensor:\n\u001B[32m--> \u001B[39m\u001B[32m460\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_conv_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/ml-lab-img/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py:456\u001B[39m, in \u001B[36mConv2d._conv_forward\u001B[39m\u001B[34m(self, input, weight, bias)\u001B[39m\n\u001B[32m    452\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.padding_mode != \u001B[33m'\u001B[39m\u001B[33mzeros\u001B[39m\u001B[33m'\u001B[39m:\n\u001B[32m    453\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m F.conv2d(F.pad(\u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m._reversed_padding_repeated_twice, mode=\u001B[38;5;28mself\u001B[39m.padding_mode),\n\u001B[32m    454\u001B[39m                     weight, bias, \u001B[38;5;28mself\u001B[39m.stride,\n\u001B[32m    455\u001B[39m                     _pair(\u001B[32m0\u001B[39m), \u001B[38;5;28mself\u001B[39m.dilation, \u001B[38;5;28mself\u001B[39m.groups)\n\u001B[32m--> \u001B[39m\u001B[32m456\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[43m.\u001B[49m\u001B[43mconv2d\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mstride\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    457\u001B[39m \u001B[43m                \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mpadding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mdilation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mgroups\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mRuntimeError\u001B[39m: Expected 3D (unbatched) or 4D (batched) input to conv2d, but got input of size: [64, 784]"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T13:25:55.449933Z",
     "start_time": "2025-04-10T13:25:55.444065Z"
    }
   },
   "cell_type": "code",
   "source": [
    "plot_learning(mnist_learning)"
   ],
   "id": "384639b55cc7c3ab",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-04-10T13:25:55.446115Z"
    }
   },
   "cell_type": "code",
   "source": [
    "saved_io = io.BytesIO()\n",
    "torch.save(model.state_dict(), saved_io)\n",
    "saved = saved_io.getvalue()\n"
   ],
   "id": "de7c859a1672879c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Now freezing common layers and optimizing the second head"
   ],
   "id": "88d1d5728b0f8f0f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-04-10T13:25:55.447406Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for parameter in model.shared_layers.parameters():\n",
    "    parameter.requires_grad = False\n",
    "    \n",
    "fmnist_learning = run_training(train_data_fmnist, test_data_fmnist, model, list(model.shared_layers.parameters()), 2)\n"
   ],
   "id": "c645bff4a60efbb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-04-10T13:25:55.448981Z"
    }
   },
   "cell_type": "code",
   "source": [
    "plot_learning(fmnist_learning)"
   ],
   "id": "831727bd5ccf8fe2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-04-10T13:25:55.450389Z"
    }
   },
   "cell_type": "code",
   "source": [],
   "id": "9968fc0ab5fdd966",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Now we are studying a second head with all layers unfrozen"
   ],
   "id": "61ad3d59fda237ac"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-04-10T13:25:55.451640Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for parameter in model.shared_layers.parameters():\n",
    "    parameter.requires_grad = True\n",
    "\n",
    "fmnist_learning_unfreezed = run_training(train_data_fmnist, test_data_fmnist, model, list(model.parameters()), 2)\n"
   ],
   "id": "3ae2733d18a94792",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T13:25:55.453972Z",
     "start_time": "2025-04-10T13:25:55.453027Z"
    }
   },
   "cell_type": "code",
   "source": [
    "plot_learning(fmnist_learning_unfreezed)\n"
   ],
   "id": "739e025c36b1b40f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-04-10T13:25:55.454726Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.load_state_dict(torch.load(io.BytesIO(saved), weights_only=True))\n",
    "model.eval()"
   ],
   "id": "f239ebe089e5f5ca",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-04-10T13:25:55.456168Z"
    }
   },
   "cell_type": "code",
   "source": [
    "fmnist_learning_unfreezed_loaded = run_training(train_data_fmnist, test_data_fmnist, model, list(model.parameters()), 2)\n"
   ],
   "id": "7c4b0eb9605478c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-04-10T13:25:55.457933Z"
    }
   },
   "cell_type": "code",
   "source": [
    "plot_learning(fmnist_learning_unfreezed_loaded)\n",
    "\n"
   ],
   "id": "a7b137bab8468995",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-04-10T13:25:55.459761Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torchvision.datasets import MNIST\n",
    "def label_names(dataset: MNIST):\n",
    "    return {idx: cls for cls, idx in dataset.class_to_idx.items()}\n",
    "    \n",
    "def find_nearest():\n",
    "    fmnist_labels = label_names(test_data_fmnist)\n",
    "    mnist_labels = label_names(test_data_mnist)\n",
    "    test_loader = torch.utils.data.DataLoader(test_data_mnist, batch_size=len(test_data_mnist), shuffle=False)\n",
    "\n",
    "    # Получение всех изображений и меток\n",
    "    images, labels = next(iter(test_loader))\n",
    "\n",
    "    # Предсказание модели (предполагаем, что model уже обучена)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(images, head=2)  # (n_samples, n_classes)\n",
    "        probabilities = torch.softmax(logits, dim=1)  # (n_samples, n_classes)\n",
    "\n",
    "    probabilities = probabilities.numpy()\n",
    "    labels = labels.numpy()\n",
    "\n",
    "    # Поиск для каждой пары классов (c, t) изображения класса c с максимальной вероятностью для t\n",
    "    n_classes = probabilities.shape[1]\n",
    "\n",
    "    for c in range(n_classes):\n",
    "        for t in range(n_classes):\n",
    "            # Маска для изображений класса c\n",
    "            mask = (labels == c)\n",
    "            probs_t = probabilities[mask, t]\n",
    "            \n",
    "            if len(probs_t) == 0:\n",
    "                continue  # Если нет изображений класса c\n",
    "            \n",
    "            # Находим индекс изображения с максимальной вероятностью для t\n",
    "            max_idx = np.argmax(probs_t)\n",
    "            \n",
    "            # Получаем все изображения класса c и выбираем нужное\n",
    "            images_c = images[mask]\n",
    "            most_similar_to_t = images_c[max_idx]\n",
    "            \n",
    "            msg= f\"Class {mnist_labels[c]} image most similar to class {fmnist_labels[t]}: prob={probs_t[max_idx]:.4f}\"\n",
    "            print()\n",
    "            \n",
    "            # Здесь можно сохранить изображение или визуализировать его\n",
    "            # Например, с помощью matplotlib:\n",
    "            # import matplotlib.pyplot as plt\n",
    "            plt.imshow(most_similar_to_t.squeeze(), cmap='gray')\n",
    "            plt.title(msg)\n",
    "            plt.show()"
   ],
   "id": "f26c695da8b878b4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-04-10T13:25:55.460928Z"
    }
   },
   "cell_type": "code",
   "source": [
    "find_nearest()"
   ],
   "id": "d06d9e671ddf9a4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-04-10T13:25:55.462325Z"
    }
   },
   "cell_type": "code",
   "source": [],
   "id": "e04a95e687dfb68a",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
